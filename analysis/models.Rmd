---
title: "Models"
output: pdf_document
date: "2022-10-30"
---

```{r setup, include=FALSE}
knitr::opts_knit$set(echo = TRUE, root.dir = 'C:/Users/jbos1/Desktop/Projects/Kaggle/spaceship-titanic/data')
```

```{r}
library(tidymodels)
library(missForest)
library(gbm)
library(doParallel)
registerDoParallel(cores=12)

ship <- read.csv('ship.csv')
```

```{r}
set.seed(3031190)
ship_train <- ship[ship$Train,]
ship_test<- ship[!ship$Train,]
```

# Lasso
```{r}
# 10_fold
ship_fold <- vfold_cv(ship_train)

# model
ls_mod <- logistic_reg(mode = "classification",
                        engine = "glmnet",
                        penalty = tune(),
                        mixture = 1 )

#recipe
ls_recipe <- recipe(Transported ~., data = ship_train) %>% 
               step_dummy(all_nominal_predictors()) %>%
               step_interact(all_predictors()) %>%
               step_normalize(all_predictors())

#workflow
ls_wflow <- workflow() %>% add_model(ls_mod) %>% add_recipe(ls_recipe)
# create grid for tuning
ls_mod_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))

# train and tun model
ls_res <- ls_wflow %>% tune_grid(resample = ship_fold ,
                                 grid = ls_mod_grid,
                                 control= control_grid(save_pred = TRUE),
                                 metrics= metric_set(roc_auc))


# The best model
top_models <-
  ls_res %>% 
  show_best("roc_auc", n = 15) %>%  # show the best 15ish models
  arrange(penalty) 
top_models

# obtain prediction



ls_final_wf <- ls_wflow %>%
    finalize_workflow(select_best(ls_res))


ls_final_fit <- ls_final_wf %>% last_fit(ship_train)
```


# gboost

# bart

